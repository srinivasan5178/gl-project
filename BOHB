import Pyro4
import ConfigSpace as CS
import numpy as np
from hpbandster.core.worker import Worker
from catboost import CatBoostClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import Sequence
from tensorflow.keras.applications import DenseNet201, EfficientNetV2L
from tensorflow.keras.regularizers import l2
import seaborn as sns
import matplotlib.pyplot as plt
import socket

# Configure Pyro4 to use the remote nameserver (ngrok)
Pyro4.config.NS_HOST = "2.tcp.ngrok.io"
Pyro4.config.NS_PORT = 18901  # The ngrok port for the Pyro4 nameserver

print(f"Pyro4 NS_HOST: {Pyro4.config.NS_HOST}")
print(f"Pyro4 NS_PORT: {Pyro4.config.NS_PORT}")


# Custom Data Generator to handle both datasets (colon and lung)
class FusionDataGenerator(Sequence):
    def __init__(self, colon_gen, lung_gen, batch_size, steps_per_epoch, num_classes=5, **kwargs):
        super().__init__(**kwargs)  # Add this line
        self.colon_gen = colon_gen
        self.lung_gen = lung_gen
        self.batch_size = batch_size
        self.steps_per_epoch = steps_per_epoch
        self.colon_iterator = iter(self.colon_gen)
        self.lung_iterator = iter(self.lung_gen)
        self.num_classes = num_classes
        self.current_index = 0

    def __len__(self):
        return self.steps_per_epoch

    def __next__(self):
        data = self.__getitem__(self.current_index)
        self.current_index += 1
        return data

    def __iter__(self):
        self.current_index = 0
        return self

    def _reset_iterators(self):
        self.colon_iterator = iter(self.colon_gen)
        self.lung_iterator = iter(self.lung_gen)
        self.current_index = 0

    def __getitem__(self, index):
        try:
            colon_batch = next(self.colon_iterator)
            lung_batch = next(self.lung_iterator)

            colon_images, colon_labels = colon_batch
            lung_images, lung_labels = lung_batch

            lung_labels = lung_labels + 2  # Adjust for correct range
            images = np.concatenate([colon_images, lung_images], axis=0)
            labels = np.concatenate([colon_labels, lung_labels], axis=0)

            return (images, labels)

        except StopIteration:
            self._reset_iterators()
            return self.__getitem__(index)


# Data generator functions for Colon and Lung datasets
def create_data_generator_colon(dataset_dir, batch_size):
    colon_datagen = ImageDataGenerator(rescale=1./255,
                                       rotation_range=40,
                                       width_shift_range=0.2,
                                       height_shift_range=0.2,
                                       shear_range=0.2,
                                       zoom_range=0.2,
                                       horizontal_flip=True,
                                       fill_mode='nearest',
                                       brightness_range=[0.8, 1.2])  # Added brightness variation

    colon_train_gen = colon_datagen.flow_from_directory(
        dataset_dir,
        target_size=(224, 224),  # EfficientNetV2L requires larger image size
        batch_size=batch_size,
        class_mode='sparse',
        classes=['colon_aca', 'colon_n'],
        shuffle=True
    )
    return colon_train_gen

def create_data_generator_lung(dataset_dir, batch_size):
    lung_datagen = ImageDataGenerator(rescale=1./255,
                                      rotation_range=40,
                                      width_shift_range=0.2,
                                      height_shift_range=0.0,
                                      shear_range=0.2,
                                      zoom_range=0.2,
                                      horizontal_flip=True,
                                      fill_mode='nearest',
                                      brightness_range=[0.8, 1.2])  # Added brightness variation

    lung_train_gen = lung_datagen.flow_from_directory(
        dataset_dir,
        target_size=(224, 224),  # DenseNet201 requires larger image size
        batch_size=batch_size,
        class_mode='sparse',
        classes=['lung_aca', 'lung_n', 'lung_scc'],
        shuffle=True
    )
    return lung_train_gen


# Build a custom CNN model from scratch using DenseNet201 for lung and EfficientNetV2L for colon
def build_cnn_model(input_shape=(224, 224, 3), learning_rate=0.0003176, num_classes=5, dropout_rate=0.5, weight_decay=1e-4, dataset_type='lung'):
    if dataset_type == 'lung':
        base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=input_shape)
    elif dataset_type == 'colon':
        base_model = EfficientNetV2L(weights='imagenet', include_top=False, input_shape=input_shape)

    # Freeze base model layers (optional)
    base_model.trainable = False

    model = models.Sequential()
    model.add(base_model)
    model.add(layers.GlobalAveragePooling2D())  # Global pooling instead of flattening
    model.add(layers.Dense(512, activation='relu', kernel_regularizer=l2(weight_decay)))  # L2 regularization
    model.add(layers.Dropout(dropout_rate))  # Dropout for regularization
    model.add(layers.Dense(256, activation='relu', kernel_regularizer=l2(weight_decay)))
    model.add(layers.Dropout(dropout_rate))
    model.add(layers.Dense(num_classes, activation='softmax'))  # For multi-class classification

    # Compile the model
    model.compile(optimizer=Adam(learning_rate=learning_rate),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

    return model


# Define hyperparameter space for optimization
def define_hyperparameter_space():
    config_space = CS.ConfigurationSpace()

    # Hyperparameters for CNN model
    learning_rate = CS.CategoricalHyperparameter('learning_rate', [0.0001, 0.001, 0.01])
    dropout_rate = CS.UniformFloatHyperparameter('dropout_rate', 0.0, 0.5)
    weight_decay = CS.UniformFloatHyperparameter('weight_decay', 1e-6, 1e-3)

    # Hyperparameters for CatBoost model
    depth = CS.UniformIntegerHyperparameter('depth', lower=10, upper=500)
    iterations = CS.UniformIntegerHyperparameter('iterations', lower=100, upper=5000)
    lr_catboost = CS.UniformFloatHyperparameter('lr_catboost', lower=0.01, upper=0.2)

    config_space.add([learning_rate, dropout_rate, weight_decay, depth, iterations, lr_catboost])  # Error fix
    return config_space


# Objective function for BOHB optimization
class CNNCatBoostWorker(Worker):
    def compute(self, config, budget, *args, **kwargs):
        # Ensure correct dataset paths are used
        colon_dataset_dir = '/content/Project_Sample/colon'
        lung_dataset_dir = '/content/Project_Sample/lung'

        # Extract hyperparameters
        learning_rate = config['learning_rate']
        dropout_rate = config['dropout_rate']
        weight_decay = config['weight_decay']
        depth = config['depth']
        iterations = config['iterations']
        lr_catboost = config['lr_catboost']

        # Create data generators
        colon_train_gen = create_data_generator_colon(colon_dataset_dir, batch_size=8)
        lung_train_gen = create_data_generator_lung(lung_dataset_dir, batch_size=8)

        # Create FusionDataGenerator for training and validation
        train_gen = FusionDataGenerator(colon_train_gen, lung_train_gen, batch_size=8, steps_per_epoch=5, num_classes=5)
        val_gen = FusionDataGenerator(colon_train_gen, lung_train_gen, batch_size=8, steps_per_epoch=5, num_classes=5)  # Use same generators for val

        # Create and compile CNN model
        cnn_model = build_cnn_model(input_shape=(224, 224, 3), learning_rate=learning_rate, num_classes=5, dropout_rate=dropout_rate, weight_decay=weight_decay)

        # **Modified CNN Training:**
        # Train the model on the combined data from the FusionDataGenerator
        history = cnn_model.fit(train_gen, epochs=70, validation_data=val_gen, steps_per_epoch=5, validation_steps=5)

        # Print training history (for debugging)
        print(history.history)

        # Extract features from CNN for CatBoost
        train_features, train_labels = extract_features_from_cnn(cnn_model, train_gen, steps=5)
        val_features, val_labels = extract_features_from_cnn(cnn_model, val_gen, steps=5)

        # Train CatBoost model
        model_catboost = CatBoostClassifier(
            iterations=iterations,
            learning_rate=lr_catboost,
            depth=depth,
            loss_function='MultiClass'
        )
        model_catboost.fit(train_features, train_labels, eval_set=(val_features, val_labels), verbose=200)

        # Save the CatBoost model
        catboost_model_filename = "catboost_model.cbm"
        model_catboost.save_model(catboost_model_filename)
        print(f"CatBoost model saved to {catboost_model_filename}")

        # Evaluate performance on validation set
        val_predictions = model_catboost.predict(val_features)
        accuracy = accuracy_score(val_labels, val_predictions)
        print(f"Validation Accuracy: {accuracy:.4f}")

        # Compute confusion matrix
        cm = confusion_matrix(val_labels, val_predictions)
        class_names = ['Colon_aca', 'Colon_n', 'Lung_aca', 'Lung_n', 'Lung_scc']  # Adjust class names based on dataset
        plot_confusion_matrix(cm, class_names)

        # Calculate accuracy on the training set
        train_predictions = model_catboost.predict(train_features)
        train_accuracy = accuracy_score(train_labels, train_predictions)
        print(f"Training Accuracy: {train_accuracy:.4f}")

        # Return result without using STATUS_OK
        return {'loss': -accuracy, 'status': 'ok'}

# Example usage:
if __name__ == "__main__":
    # Instantiate the worker and define the hyperparameter space
    worker = CNNCatBoostWorker(run_id="worker_1")
    config_space = define_hyperparameter_space()

    # Test the worker's computation method
    config = {'learning_rate': 0.001, 'dropout_rate': 0.3, 'weight_decay': 1e-5, 'depth': 10, 'iterations': 1000, 'lr_catboost': 0.1}
    result = worker.compute(config=config, budget=25)
    print(result)
