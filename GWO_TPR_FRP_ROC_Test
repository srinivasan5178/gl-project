# EfficientNetV2L/V2M + DenseNet201 Fusion with CatBoost & GWO - FINAL VERSION -010525
# GWO/TPR/FRP/ROC/Test-validation
import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Dense, Dropout, Concatenate, BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import mixed_precision
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import DenseNet201, EfficientNetV2L, EfficientNetV2M
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, roc_curve
from sklearn.utils.class_weight import compute_class_weight
from sklearn.preprocessing import label_binarize
from catboost import CatBoostClassifier
import splitfolders
import time

# Set mixed precision
tf.keras.backend.clear_session()
policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_global_policy(policy)

original_dataset_dir = "/content/Project_Sample"
split_dataset_dir = "/content/Project_Sample_split"

# Dataset split
splitfolders.ratio(os.path.join(original_dataset_dir, 'colon'), output=os.path.join(split_dataset_dir, 'colon'), seed=42, ratio=(.7, .15, .15))
splitfolders.ratio(os.path.join(original_dataset_dir, 'lung'), output=os.path.join(split_dataset_dir, 'lung'), seed=42, ratio=(.7, .15, .15))

# Fusion generator
class FusionDataGenerator(tf.keras.utils.Sequence):
    def __init__(self, colon_gen, lung_gen, batch_size, steps_per_epoch, num_classes=5):
        self.colon_gen = colon_gen
        self.lung_gen = lung_gen
        self.batch_size = batch_size
        self.steps_per_epoch = steps_per_epoch
        self.num_classes = num_classes
        self._reset_iterators()

    def __len__(self):
        return self.steps_per_epoch

    def __getitem__(self, index):
        try:
            colon_images, colon_labels = next(self.colon_iterator)
            lung_images, lung_labels = next(self.lung_iterator)
            lung_labels += 2

            images = np.concatenate([colon_images, lung_images], axis=0)
            labels = np.concatenate([colon_labels, lung_labels], axis=0)

            colon_images = tf.convert_to_tensor(images, dtype=tf.float32)
            lung_images = tf.convert_to_tensor(images, dtype=tf.float32)
            labels = tf.convert_to_tensor(labels, dtype=tf.int32)

            return (colon_images, lung_images), labels
        except StopIteration:
            self._reset_iterators()
            return self.__getitem__(index)

    def _reset_iterators(self):
        self.colon_iterator = iter(self.colon_gen)
        self.lung_iterator = iter(self.lung_gen)

# Data generator
def create_data_generator(dataset_dir, class_list, batch_size):
    datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2,
                                 height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,
                                 horizontal_flip=True, fill_mode='nearest')
    return datagen.flow_from_directory(dataset_dir, target_size=(64, 64), batch_size=batch_size,
                                       class_mode='sparse', classes=class_list, shuffle=True)

# Base model
def create_base_model(base_model, input_shape=(64, 64, 3), output_dim=128):
    for layer in base_model.layers[:400]:
        layer.trainable = False
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dropout(0.5)(x)
    x = Dense(output_dim, activation='relu')(x)
    return Model(inputs=base_model.input, outputs=x)

# Fusion model
def build_model(dense1_units=512, dropout_rate=0.2, learning_rate=0.0003176, num_classes=5):
    input_colon = Input(shape=(64, 64, 3))
    input_lung = Input(shape=(64, 64, 3))
    base1 = create_base_model(DenseNet201(weights='imagenet', include_top=False, input_shape=(64, 64, 3)))
    base2 = create_base_model(EfficientNetV2M(weights='imagenet', include_top=False, input_shape=(64, 64, 3)))

    features1 = base1(input_colon)
    features2 = base2(input_lung)
    merged = Concatenate()([features1, features2])
    x = BatchNormalization()(merged)
    x = Dense(dense1_units, activation='relu')(x)
    x = Dropout(dropout_rate)(x)
    x = BatchNormalization()(x)
    x = Dense(256, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Dense(128, activation='relu')(x)
    output = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs=[input_colon, input_lung], outputs=output)
    model.compile(optimizer=Adam(learning_rate=learning_rate),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# Feature extractor
def extract_features(model, generator, steps):
    feature_model = Model(inputs=model.input, outputs=model.get_layer(index=-2).output)
    features, labels = [], []
    for _ in range(steps):
        (x1, x2), y = generator[_]
        feature = feature_model.predict([x1, x2], verbose=0)
        features.append(feature)
        labels.append(y)
    return np.vstack(features), np.hstack(labels)

# Metrics
def evaluate_metrics(y_true, y_pred, name):
    print(f"\n{name} Metrics:")
    print(f"Accuracy:  {accuracy_score(y_true, y_pred) * 100:.2f}%")
    print(f"Precision: {precision_score(y_true, y_pred, average='weighted'):.4f}")
    print(f"Recall:    {recall_score(y_true, y_pred, average='weighted'):.4f}")
    print(f"F1 Score:  {f1_score(y_true, y_pred, average='weighted'):.4f}")

def show_conf_matrix_and_report(y_true, y_pred, dataset_name):
    class_names = ['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc']
    print(f"\n--- {dataset_name} Classification Report ---")
    print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))
    cm = confusion_matrix(y_true, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    fig, ax = plt.subplots(figsize=(8, 6))
    disp.plot(ax=ax, cmap=plt.cm.Blues, values_format='d')
    plt.title(f"{dataset_name} Confusion Matrix")
    plt.tight_layout()
    plt.show()

def plot_roc_curve(y_true_bin, y_score, name):
    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    n_classes = y_true_bin.shape[1]
    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_score[:, i])
        roc_auc[i] = roc_auc_score(y_true_bin[:, i], y_score[:, i])

    plt.figure(figsize=(8, 6))
    for i in range(n_classes):
        plt.plot(fpr[i], tpr[i], label=f"Class {i} AUC = {roc_auc[i]:.2f}")
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title(f"{name} ROC Curve")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# GWO
def catboost_objective(params):
    lr, depth, l2_leaf = params
    model = CatBoostClassifier(learning_rate=lr, depth=int(depth), l2_leaf_reg=l2_leaf, verbose=0)
    model.fit(X_train, y_train)
    preds = model.predict(X_val)
    return 1 - accuracy_score(y_val, preds)

def gwo(objective, dim, bounds, num_agents=3, max_iter=3):
    Alpha_pos, Beta_pos, Delta_pos = np.zeros(dim), np.zeros(dim), np.zeros(dim)
    Alpha_score = Beta_score = Delta_score = float("inf")
    Positions = np.random.rand(num_agents, dim)
    for i in range(dim):
        Positions[:, i] = Positions[:, i] * (bounds[i][1] - bounds[i][0]) + bounds[i][0]

    for t in range(max_iter):
        for i in range(num_agents):
            fitness = objective(Positions[i])
            if fitness < Alpha_score:
                Alpha_score, Alpha_pos = fitness, Positions[i].copy()
            elif fitness < Beta_score:
                Beta_score, Beta_pos = fitness, Positions[i].copy()
            elif fitness < Delta_score:
                Delta_score, Delta_pos = fitness, Positions[i].copy()

        a = 2 - t * (2 / max_iter)
        for i in range(num_agents):
            for j in range(dim):
                r1, r2 = np.random.rand(), np.random.rand()
                A1, C1 = 2 * a * r1 - a, 2 * r2
                D_alpha = abs(C1 * Alpha_pos[j] - Positions[i, j])
                X1 = Alpha_pos[j] - A1 * D_alpha

                r1, r2 = np.random.rand(), np.random.rand()
                A2, C2 = 2 * a * r1 - a, 2 * r2
                D_beta = abs(C2 * Beta_pos[j] - Positions[i, j])
                X2 = Beta_pos[j] - A2 * D_beta

                r1, r2 = np.random.rand(), np.random.rand()
                A3, C3 = 2 * a * r1 - a, 2 * r2
                D_delta = abs(C3 * Delta_pos[j] - Positions[i, j])
                X3 = Delta_pos[j] - A3 * D_delta

                Positions[i, j] = np.clip((X1 + X2 + X3) / 3.0, bounds[j][0], bounds[j][1])

    return Alpha_pos, Alpha_score

# Training
batch_size = 8
steps_per_epoch = 50
val_steps = 20

colon_train_gen = create_data_generator(os.path.join(split_dataset_dir, "colon/train"), ['colon_aca', 'colon_n'], batch_size)
lung_train_gen = create_data_generator(os.path.join(split_dataset_dir, "lung/train"), ['lung_aca', 'lung_n', 'lung_scc'], batch_size)
colon_val_gen = create_data_generator(os.path.join(split_dataset_dir, "colon/val"), ['colon_aca', 'colon_n'], batch_size)
lung_val_gen = create_data_generator(os.path.join(split_dataset_dir, "lung/val"), ['lung_aca', 'lung_n', 'lung_scc'], batch_size)

train_gen = FusionDataGenerator(colon_train_gen, lung_train_gen, batch_size, steps_per_epoch)
val_gen = FusionDataGenerator(colon_val_gen, lung_val_gen, batch_size, val_steps)

model = build_model()
callbacks = [EarlyStopping(patience=5, restore_best_weights=True), ReduceLROnPlateau(factor=0.2, patience=3, min_lr=1e-6)]

model.fit(train_gen, validation_data=val_gen, epochs=10, callbacks=callbacks)

X_train, y_train = extract_features(model, train_gen, len(train_gen))
X_val, y_val = extract_features(model, val_gen, len(val_gen))

bounds = [(0.01, 0.2), (4, 10), (1, 10)]
best_params, _ = gwo(catboost_objective, dim=3, bounds=bounds)

class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
class_weights_dict = {i: w for i, w in enumerate(class_weights)}

cat_model = CatBoostClassifier(learning_rate=best_params[0], depth=int(best_params[1]),
                                l2_leaf_reg=best_params[2], class_weights=class_weights_dict, verbose=0)

start_train = time.time()
cat_model.fit(X_train, y_train)
train_duration = time.time() - start_train

start_val = time.time()
y_train_pred = cat_model.predict(X_train)
y_val_pred = cat_model.predict(X_val)
val_duration = time.time() - start_val

evaluate_metrics(y_train, y_train_pred, "Training")
evaluate_metrics(y_val, y_val_pred, "Validation")
print(f"\nTraining time: {train_duration:.2f}s")
print(f"Validation time: {val_duration:.2f}s")
show_conf_matrix_and_report(y_val, y_val_pred, "Validation")

# TEST PHASE
colon_test_gen = create_data_generator(os.path.join(split_dataset_dir, "colon/test"), ['colon_aca', 'colon_n'], batch_size)
lung_test_gen = create_data_generator(os.path.join(split_dataset_dir, "lung/test"), ['lung_aca', 'lung_n', 'lung_scc'], batch_size)
test_gen = FusionDataGenerator(colon_test_gen, lung_test_gen, batch_size, val_steps)

X_test, y_test = extract_features(model, test_gen, len(test_gen))
y_test_pred = cat_model.predict(X_test)

evaluate_metrics(y_test, y_test_pred, "Test")
show_conf_matrix_and_report(y_test, y_test_pred, "Test")

y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3, 4])
y_test_proba = cat_model.predict_proba(X_test)
plot_roc_curve(y_test_bin, y_test_proba, "Test")

# Save CatBoost model
cat_model.save_model("catboost_fusion_model.cbm")
print("Model saved as 'catboost_fusion_model.cbm'")


##### Validation Testing#####
# === Validation # 300425

import os
import numpy as np
import pandas as pd
from tensorflow.keras.applications import DenseNet201, EfficientNetV2L
from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense, Concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing import image
from catboost import CatBoostClassifier
import tensorflow as tf

# --- Paths ---
colon_folder = '/content/colon_validation'
lung_folder = '/content/lung_validation'
catboost_model_path = '/content/catboost_fusion_model.cbm'
output_csv = 'catboost_validation_only_predictions.csv'

# --- Class labels ---
class_names = ['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc']

# --- Image preprocessing ---
def preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(64, 64))
    img_array = image.img_to_array(img) / 255.0
    return np.expand_dims(img_array, axis=0)

# --- Rebuild feature extractor model ---
def build_feature_extractor():
    input_shape = (64, 64, 3)
    colon_input = tf.keras.Input(shape=input_shape)
    lung_input = tf.keras.Input(shape=input_shape)

    base_colon = DenseNet201(weights='imagenet', include_top=False, input_shape=input_shape)
    base_lung = EfficientNetV2L(weights='imagenet', include_top=False, input_shape=input_shape)

    for layer in base_colon.layers[:400]:
        layer.trainable = False

    colon_feat = base_colon(colon_input)
    colon_feat = GlobalAveragePooling2D()(colon_feat)
    colon_feat = Dropout(0.5)(colon_feat)
    colon_feat = Dense(128, activation='relu')(colon_feat)

    lung_feat = base_lung(lung_input)
    lung_feat = GlobalAveragePooling2D()(lung_feat)
    lung_feat = Dropout(0.5)(lung_feat)
    lung_feat = Dense(128, activation='relu')(lung_feat)

    merged_feat = Concatenate()([colon_feat, lung_feat])
    model = Model(inputs=[colon_input, lung_input], outputs=merged_feat)
    return model

# --- Load feature extractor and CatBoost ---
feature_extractor = build_feature_extractor()
cat_model = CatBoostClassifier()
cat_model.load_model(catboost_model_path)

# --- Validation loop ---
colon_images = sorted(os.listdir(colon_folder))
lung_images = sorted(os.listdir(lung_folder))
num_samples = min(len(colon_images), len(lung_images))

results = []

for i in range(num_samples):
    colon_img_path = os.path.join(colon_folder, colon_images[i])
    lung_img_path = os.path.join(lung_folder, lung_images[i])

    colon_img = preprocess_image(colon_img_path)
    lung_img = preprocess_image(lung_img_path)

    features = feature_extractor.predict([colon_img, lung_img], verbose=0)
    pred_idx = int(cat_model.predict(features)[0])
    pred_class = class_names[pred_idx]

    results.append({
        "colon_image": colon_images[i],
        "lung_image": lung_images[i],
        "predicted_class": pred_class
    })

# --- Save results ---
df = pd.DataFrame(results)
df.to_csv(output_csv, index=False)
print(f"CatBoost predictions saved to '{output_csv}'")
