# updated_full_balanced_pipeline_gwo_macrof1_catboost_weights.py
import os
import shutil
import random
import time
import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore")

import tensorflow as tf
from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Dense, Dropout, Concatenate, BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import DenseNet201, EfficientNetV2M

from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay,
                             classification_report, precision_score, recall_score,
                             f1_score, accuracy_score)
from sklearn.utils.class_weight import compute_class_weight

from catboost import CatBoostClassifier

# -------------------------
# USER CONFIG
# -------------------------
original_dataset_dir = "/content/Project_Sample"        # original dataset (domains: colon/, lung/) OR flat classes
balanced_temp_dir   = "/content/Project_Sample_balanced" # temp oversampled dataset root
split_dataset_dir   = "/content/Project_Sample_split_bal" # final train/val/test (balanced)
plots_dir = "./plots"
os.makedirs(plots_dir, exist_ok=True)

RATIO = (0.7, 0.15, 0.15)  # train, val, test per-class ratio
SEED = 42
batch_size = 8
epochs = 3   # change to larger value when ready

GWO_AGENTS = 5  # increase for better search (slower)
GWO_ITERS = 5   # increase for better search (slower)

random.seed(SEED)
np.random.seed(SEED)

# -------------------------
# UTILITIES
# -------------------------
def clean_folder(path):
    if os.path.exists(path):
        shutil.rmtree(path)
    os.makedirs(path, exist_ok=True)

def list_subdirs(path):
    if not os.path.exists(path):
        return []
    return sorted([d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))])

# -------------------------
# OVERSAMPLE (flat per-class) - robust: works whether input has domains or flat classes
# This ensures each class (colon_aca, colon_n, lung_aca, lung_n, lung_scc) gets max_count samples
# -------------------------
def oversample_all_classes_flat(input_root, balanced_root, seed=SEED):
    random.seed(seed)
    np.random.seed(seed)

    clean_folder(balanced_root)

    # Try to find per-domain structure first (colon/, lung/). If present, flatten to class list.
    domains = list_subdirs(input_root)
    classes = []
    if domains:
        # collect classes under domains
        for dom in domains:
            dom_path = os.path.join(input_root, dom)
            subcls = list_subdirs(dom_path)
            if subcls:
                for sc in subcls:
                    classes.append((dom, sc, os.path.join(dom_path, sc)))
            else:
                # domain may directly contain images (unlikely), skip
                pass
        # produce mapping class_name -> files
        files_per_class = {}
        for dom, cls, cls_path in classes:
            class_name = cls if cls.startswith(dom + "_") == False else cls
            files = [os.path.join(cls_path, f) for f in os.listdir(cls_path) if os.path.isfile(os.path.join(cls_path, f))]
            files_per_class[class_name] = files
    else:
        # flat class folders under input_root
        cls_list = list_subdirs(input_root)
        files_per_class = {}
        for cls in cls_list:
            cls_path = os.path.join(input_root, cls)
            files = [os.path.join(cls_path, f) for f in os.listdir(cls_path) if os.path.isfile(os.path.join(cls_path, f))]
            files_per_class[cls] = files

    if not files_per_class:
        raise ValueError(f"No class folders found under {input_root}. Expected class dirs like 'colon_aca', 'lung_scc', etc.")

    # compute max_count
    max_count = max(len(v) for v in files_per_class.values() if len(v) > 0)
    if max_count == 0:
        raise ValueError("No image files found in any class folder.")

    print("Classes found and file counts:")
    for k, v in files_per_class.items():
        print(f"  {k}: {len(v)}")

    print(f"Oversampling all classes to {max_count} samples each...")

    for cls, files in files_per_class.items():
        out_dir = os.path.join(balanced_root, cls)
        os.makedirs(out_dir, exist_ok=True)
        if len(files) == 0:
            print(f"  Warning: class {cls} has 0 files; skipping.")
            continue
        replicated = []
        while len(replicated) < max_count:
            replicated.extend(files)
        replicated = replicated[:max_count]
        for idx, src in enumerate(replicated):
            ext = os.path.splitext(src)[1]
            dst = os.path.join(out_dir, f"{cls}_{idx}{ext}")
            shutil.copy2(src, dst)
    print("Oversampling complete.")

# -------------------------
# Split balanced into train/val/test (per-class balanced)
# -------------------------
def split_balanced_to_train_val_test(balanced_root, output_root, ratio=RATIO, seed=SEED):
    random.seed(seed)
    np.random.seed(seed)

    if not os.path.exists(balanced_root):
        raise ValueError(f"Balanced root not found: {balanced_root}")

    clean_folder(output_root)
    classes = list_subdirs(balanced_root)
    for cls in classes:
        cls_path = os.path.join(balanced_root, cls)
        files = [os.path.join(cls_path, f) for f in os.listdir(cls_path) if os.path.isfile(os.path.join(cls_path, f))]
        random.shuffle(files)
        n_total = len(files)
        n_train = int(np.floor(n_total * ratio[0]))
        n_val = int(np.floor(n_total * ratio[1]))
        n_test = n_total - n_train - n_val

        for split_name, flist in [('train', files[:n_train]), ('val', files[n_train:n_train+n_val]), ('test', files[n_train+n_val:])]:
            out_dir = os.path.join(output_root, split_name, cls)
            os.makedirs(out_dir, exist_ok=True)
            for f in flist:
                shutil.copy2(f, out_dir)
        print(f"{cls}: total={n_total} -> train={n_train}, val={n_val}, test={n_test}")

# -------------------------
# ImageDataGenerator factory
# -------------------------
def create_data_generator(dataset_dir, class_list, batch_size, shuffle=True):
    if not os.path.exists(dataset_dir):
        raise ValueError(f"Dataset directory does not exist: {dataset_dir}")

    # quick sanity check
    found_any = False
    missing = []
    for cls in class_list:
        cls_path = os.path.join(dataset_dir, cls)
        if os.path.isdir(cls_path) and any(os.path.isfile(os.path.join(cls_path, f)) for f in os.listdir(cls_path)):
            found_any = True
        else:
            missing.append(cls_path)
    if not found_any:
        raise ValueError(f"No class subfolders with files found in {dataset_dir}. Missing (or empty): {missing}")

    datagen = ImageDataGenerator(rescale=1./255,
                                 rotation_range=20,
                                 width_shift_range=0.1,
                                 height_shift_range=0.1,
                                 shear_range=0.1,
                                 zoom_range=0.1,
                                 horizontal_flip=True,
                                 fill_mode='nearest')
    gen = datagen.flow_from_directory(dataset_dir,
                                      target_size=(64,64),
                                      batch_size=batch_size,
                                      class_mode='sparse',
                                      classes=class_list,
                                      shuffle=shuffle)
    if getattr(gen, "samples", 0) == 0:
        raise ValueError(f"Generator for {dataset_dir} has 0 samples (check path/class list).")
    return gen

# -------------------------
# Single-branch approach while preserving fusion architecture (feed same image to both inputs)
# We'll create ONE generator for all classes and feed (images, images) to the fusion model
# -------------------------
class SimplePairGenerator(tf.keras.utils.Sequence):
    def __init__(self, image_gen):
        self.image_gen = image_gen
        self.steps = len(self.image_gen)
    def __len__(self):
        return int(self.steps)
    def __getitem__(self, idx):
        x, y = self.image_gen[idx]
        # feed same image to both inputs
        return (x, x), y

# -------------------------
# Fusion model (Option D) - unchanged
# -------------------------
def create_base_model(base_model, input_shape=(64,64,3), output_dim=128):
    for layer in base_model.layers[:400]:
        layer.trainable = False
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dropout(0.5)(x)
    x = Dense(output_dim, activation='relu')(x)
    return Model(inputs=base_model.input, outputs=x)

def build_model(dense1_units=512, dropout_rate=0.2, learning_rate=0.0003176, num_classes=5):
    input_a = Input(shape=(64,64,3))
    input_b = Input(shape=(64,64,3))

    base1 = create_base_model(DenseNet201(weights='imagenet', include_top=False, input_shape=(64,64,3)))
    base2 = create_base_model(EfficientNetV2M(weights='imagenet', include_top=False, input_shape=(64,64,3), include_preprocessing=False))

    f1 = base1(input_a)
    f2 = base2(input_b)

    merged = Concatenate()([f1, f2])
    x = BatchNormalization()(merged)
    x = Dense(dense1_units, activation='relu')(x)
    x = Dropout(dropout_rate)(x)
    x = BatchNormalization()(x)
    x = Dense(256, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Dense(128, activation='relu')(x)

    output = Dense(num_classes, activation='softmax')(x)
    model = Model(inputs=[input_a, input_b], outputs=output)
    model.compile(optimizer=Adam(learning_rate=learning_rate),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# -------------------------
# Feature extraction: use the trained fusion model and get penultimate layer output
# -------------------------
def extract_features_from_fusion_model(model, pair_generator):
    feature_model = Model(inputs=model.input, outputs=model.layers[-2].output)
    feats, labs = [], []
    for i in range(len(pair_generator)):
        (x1, x2), y = pair_generator[i]
        f = feature_model.predict([x1, x2], verbose=0)
        feats.append(f)
        labs.append(y)
    if len(feats) == 0:
        return np.empty((0,)), np.empty((0,))
    return np.vstack(feats), np.hstack(labs)

# -------------------------
# GWO: optimize CatBoost hyperparams using macro-F1 as fitness (balanced)
# Note: objective returns lower-is-better, so we return 1 - macro_f1
# -------------------------
def gwo(objective, dim, bounds, num_agents=5, max_iter=5):
    Alpha_pos = np.zeros(dim)
    Beta_pos = np.zeros(dim)
    Delta_pos = np.zeros(dim)
    Alpha_score = Beta_score = Delta_score = float("inf")

    Positions = np.random.rand(num_agents, dim)
    for i in range(dim):
        Positions[:, i] = Positions[:, i] * (bounds[i][1] - bounds[i][0]) + bounds[i][0]

    for t in range(max_iter):
        for i in range(num_agents):
            fitness = objective(Positions[i])
            if fitness < Alpha_score:
                Alpha_score, Alpha_pos = fitness, Positions[i].copy()
            elif fitness < Beta_score:
                Beta_score, Beta_pos = fitness, Positions[i].copy()
            elif fitness < Delta_score:
                Delta_score, Delta_pos = fitness, Positions[i].copy()

        a = 2 - t * (2 / max_iter)
        for i in range(num_agents):
            for j in range(dim):
                r1, r2 = np.random.rand(), np.random.rand()
                A1, C1 = 2 * a * r1 - a, 2 * r2
                D_alpha = abs(C1 * Alpha_pos[j] - Positions[i, j])
                X1 = Alpha_pos[j] - A1 * D_alpha

                r1, r2 = np.random.rand(), np.random.rand()
                A2, C2 = 2 * a * r1 - a, 2 * r2
                D_beta = abs(C2 * Beta_pos[j] - Positions[i, j])
                X2 = Beta_pos[j] - A2 * D_beta

                r1, r2 = np.random.rand(), np.random.rand()
                A3, C3 = 2 * a * r1 - a, 2 * r2
                D_delta = abs(C3 * Delta_pos[j] - Positions[i, j])
                X3 = Delta_pos[j] - A3 * D_delta

                Positions[i, j] = np.clip((X1 + X2 + X3) / 3.0, bounds[j][0], bounds[j][1])

    return Alpha_pos, Alpha_score

# -------------------------
# Metrics helpers
# -------------------------
def evaluate_metrics(y_true, y_pred, name):
    print(f"\n{name} Metrics:")
    print(f"Accuracy:  {accuracy_score(y_true, y_pred) * 100:.2f}%")
    print(f"Precision: {precision_score(y_true, y_pred, average='weighted'):.4f}")
    print(f"Recall:    {recall_score(y_true, y_pred, average='weighted'):.4f}")
    print(f"F1 Score:  {f1_score(y_true, y_pred, average='weighted'):.4f}")

def show_conf_matrix_and_report(y_true, y_pred, dataset_name):
    class_names = ['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc']
    print(f"\n--- {dataset_name} Classification Report ---")
    print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))
    cm = confusion_matrix(y_true, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    fig, ax = plt.subplots(figsize=(8,6))
    disp.plot(ax=ax, cmap=plt.cm.Blues, values_format='d')
    plt.title(f"{dataset_name} Confusion Matrix")
    plt.tight_layout()
    plt.show()

# -------------------------
# MAIN
# -------------------------
if __name__ == "__main__":
    # 1) Oversample flat per-class (robust)
    print("\nSTEP 1: Oversampling (flat per-class) to balanced_temp_dir ...")
    oversample_all_classes_flat(original_dataset_dir, balanced_temp_dir, seed=SEED)

    # 2) Split balanced -> split_dataset_dir
    print("\nSTEP 2: Splitting balanced dataset into train/val/test (per-class balanced)...")
    split_balanced_to_train_val_test(balanced_temp_dir, split_dataset_dir, ratio=RATIO, seed=SEED)

    # 3) Quick summary (sanity)
    print("\n--- Quick summary of final split counts (split, class) ---")
    for split in ['train','val','test']:
        spath = os.path.join(split_dataset_dir, split)
        if not os.path.exists(spath): continue
        for cls in sorted(os.listdir(spath)):
            cls_path = os.path.join(spath, cls)
            cnt = len([f for f in os.listdir(cls_path) if os.path.isfile(os.path.join(cls_path, f))])
            print((split, cls), cnt)

    # 4) Create ImageDataGenerator for all classes and wrap into SimplePairGenerator
    class_list = sorted(list_subdirs(balanced_temp_dir))  # class folder names
    if not class_list:
        # fallback: look at split dir
        class_list = sorted(list_subdirs(os.path.join(split_dataset_dir, 'train')))
    print("\nClasses to use:", class_list)

    train_dir = os.path.join(split_dataset_dir, 'train')
    val_dir   = os.path.join(split_dataset_dir, 'val')
    test_dir  = os.path.join(split_dataset_dir, 'test')

    train_img_gen = create_data_generator(train_dir, class_list, batch_size, shuffle=True)
    val_img_gen   = create_data_generator(val_dir, class_list, batch_size, shuffle=False)
    test_img_gen  = create_data_generator(test_dir, class_list, batch_size, shuffle=False)

    train_gen = SimplePairGenerator(train_img_gen)
    val_gen   = SimplePairGenerator(val_img_gen)
    test_gen  = SimplePairGenerator(test_img_gen)

    print(f"\nTrain samples: {train_img_gen.samples}, Val samples: {val_img_gen.samples}, Test samples: {test_img_gen.samples}")

    # 5) Build and train fusion model (we feed same image into both inputs)
    print("\nSTEP 3: Building & training fusion model (feeding same image into both inputs)...")
    model = build_model(num_classes=len(class_list))

    es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)
    rlp = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1)
    mcp = ModelCheckpoint('best_fusion_model.h5', monitor='val_loss', save_best_only=True, verbose=1)
    callbacks = [es, rlp, mcp]

    history = model.fit(
        train_gen,
        validation_data=val_gen,
        epochs=epochs,
        callbacks=callbacks,
        steps_per_epoch=len(train_gen),
        validation_steps=len(val_gen),
        verbose=1
    )

    # 6) Extract features from trained model (after training) using balanced generators
    print("\nSTEP 4: Extracting features from the trained fusion model (balanced generators)...")
    X_train_feats, y_train_feats = extract_features_from_fusion_model(model, train_gen)
    X_val_feats,   y_val_feats   = extract_features_from_fusion_model(model, val_gen)
    X_test_feats,  y_test_feats  = extract_features_from_fusion_model(model, test_gen)

    print("Feature shapes (train/val/test):", X_train_feats.shape, X_val_feats.shape, X_test_feats.shape)
    unique, counts = np.unique(y_val_feats, return_counts=True)
    print("Validation feature class supports:", dict(zip(unique.astype(int), counts.astype(int))))

    # 7) GWO objective â€” optimize macro-F1 on validation features (balanced)
    def catboost_objective_macrof1(params):
        lr = float(params[0])
        depth = int(round(params[1]))
        l2_leaf = float(params[2])

        # compute class weights from balanced training features (ensures CatBoost uses weights)
        classes = np.unique(y_train_feats)
        cw = compute_class_weight('balanced', classes=classes, y=y_train_feats)
        cw_list = [float(w) for w in cw]

        mdl = CatBoostClassifier(learning_rate=lr, depth=depth, l2_leaf_reg=l2_leaf,
                                 class_weights=cw_list, verbose=0, random_state=SEED)
        mdl.fit(X_train_feats, y_train_feats)
        preds = mdl.predict(X_val_feats)
        macro_f1 = f1_score(y_val_feats, preds, average='macro')
        # objective must be minimized
        return 1.0 - macro_f1

    print("\nSTEP 5: Running GWO for CatBoost hyperparameters (optimizing macro-F1)...")
    bounds = [(0.01, 0.2), (4, 10), (1, 10)]
    best_pos, best_score = gwo(catboost_objective_macrof1, dim=3, bounds=bounds, num_agents=GWO_AGENTS, max_iter=GWO_ITERS)
    best_lr = float(best_pos[0])
    best_depth = int(round(best_pos[1]))
    best_l2 = float(best_pos[2])
    print(f"GWO best found: lr={best_lr:.4f}, depth={best_depth}, l2_leaf={best_l2:.4f} (1-macroF1={best_score:.4f})")

    # 8) Train final CatBoost with the found hyperparams and class weights
    print("\nSTEP 6: Training final CatBoost with class weights (on balanced features)...")
    classes = np.unique(y_train_feats)
    cw = compute_class_weight('balanced', classes=classes, y=y_train_feats)
    cw_list = [float(w) for w in cw]
    print("Class weights used:", dict(zip(classes.astype(int), cw_list)))

    cat_model = CatBoostClassifier(learning_rate=best_lr, depth=best_depth, l2_leaf_reg=best_l2,
                                   class_weights=cw_list, verbose=0, random_state=SEED)
    t0 = time.time()
    cat_model.fit(X_train_feats, y_train_feats)
    print("CatBoost training time: {:.2f}s".format(time.time() - t0))

    # 9) Evaluate
    y_val_pred = cat_model.predict(X_val_feats)
    y_test_pred = cat_model.predict(X_test_feats)

    evaluate_metrics(y_val_feats, y_val_pred, "Validation")
    show_conf_matrix_and_report(y_val_feats, y_val_pred, "Validation (balanced features)")

    evaluate_metrics(y_test_feats, y_test_pred, "Test")
    show_conf_matrix_and_report(y_test_feats, y_test_pred, "Test (balanced features)")

    # Save CatBoost model
    cat_model.save_model("catboost_fusion_model_macrof1_weights.cbm")
    print("Saved CatBoost model to catboost_fusion_model_macrof1_weights.cbm")

    print("\nALL DONE. If any class support still looks wrong, check the 'Quick summary' printed earlier and ensure no old cached feature files are being used.")
